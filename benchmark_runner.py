import subprocess
import time
import re
import os
import tempfile
from datetime import datetime
import psycopg2
from config import DB_CONFIG

class BenchmarkRunner:
    def __init__(self, db_config):
        self.db_config = db_config
        self.container_name = "vtb_postgres"
        self.hammerdb_container = "vtb_hammerdb"

    def _copy_script_to_container(self, script_content, script_name="test.sql"):
        """
        –°–æ–∑–¥–∞–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª —Å–æ —Å–∫—Ä–∏–ø—Ç–æ–º –∏ –∫–æ–ø–∏—Ä—É–µ—Ç –µ–≥–æ –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä.
        –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç pgbench –∏—Å–ø–æ–ª–Ω—è—Ç—å —Å–∫—Ä–∏–ø—Ç –ª–æ–∫–∞–ª—å–Ω–æ –±–µ–∑ —Å–µ—Ç–µ–≤—ã—Ö –∑–∞–¥–µ—Ä–∂–µ–∫.
        """
        try:
            with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.sql') as tmp:
                tmp.write(script_content)
                tmp_path = tmp.name

            docker_dest = f"{self.container_name}:/tmp/{script_name}"
            subprocess.run(["docker", "cp", tmp_path, docker_dest], check=True)

            os.remove(tmp_path)

            return f"/tmp/{script_name}"
        except Exception as e:
            print(f" Error copying script to docker: {e}")
            return None

    def _run_pgbench_custom(self, script_path, duration, clients, threads, test_name):
        """
        –ó–∞–ø—É—Å–∫–∞–µ—Ç pgbench –≤–Ω—É—Ç—Ä–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ —Å —É–∫–∞–∑–∞–Ω–Ω—ã–º —Å–∫—Ä–∏–ø—Ç–æ–º.
        """
        cmd = [
            "docker", "exec", "-i", self.container_name,
            "pgbench",
            "-U", "user",
            "-d", "mydb",
            "-T", str(duration),
            "-c", str(clients),
            "-j", str(threads),
            "-P", "5",
            "-f", script_path,
            "-r"
        ]

        print(f"üîß Running {test_name}: pgbench -c {clients} -j {threads} -T {duration} ...")

        result = subprocess.run(cmd, capture_output=True, text=True)
        return result

    def run_oltp_test(self, profile_name, duration=30, clients=20):
        """
        –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π TPC-B –ø–æ–¥–æ–±–Ω—ã–π —Ç–µ—Å—Ç (—á—Ç–µ–Ω–∏–µ + –∑–∞–ø–∏—Å—å –≤ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏).
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π —Å—Ü–µ–Ω–∞—Ä–∏–π pgbench.
        """
        try:
            print(f" Starting OLTP test for {profile_name}...")

            self._initialize_pgbench(scale=10)

            cmd = [
                "docker", "exec", "-i", self.container_name,
                "pgbench",
                "-c", str(clients),
                "-j", "4",
                "-T", str(duration),
                "-U", "user", "mydb",
                "-r", "-P", "5"
            ]

            result = subprocess.run(cmd, capture_output=True, text=True)
            return self._process_results(result.stdout, profile_name, "OLTP", duration, clients)

        except Exception as e:
            return self._handle_error(e, profile_name)

    def run_olap_test(self, profile_name, duration=30):
        """
        –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞: —Å–ª–æ–∂–Ω—ã–µ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ –∏ JOIN'—ã.
        """
        try:
            print(f" Starting OLAP test for {profile_name}...")
            self._create_olap_indexes()

            sql_script = """
            \set r random(1, 3)
            \if :r = 1
                -- –ê–≥—Ä–µ–≥–∞—Ü–∏—è –ø–æ –≤—Å–µ–º —Å—á–µ—Ç–∞–º
                SELECT bid, count(*), avg(abalance) FROM pgbench_accounts GROUP BY bid;
            \elif :r = 2
                -- JOIN —Ç—Ä–µ—Ö —Ç–∞–±–ª–∏—Ü
                SELECT a.aid, b.bbalance, t.tbalance
                FROM pgbench_accounts a
                JOIN pgbench_branches b ON a.bid = b.bid
                JOIN pgbench_tellers t ON a.bid = t.bid
                WHERE a.abalance > 0 LIMIT 100;
            \else
                -- –û–∫–æ–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ (–µ—Å–ª–∏ –≤–µ—Ä—Å–∏—è PG –ø–æ–∑–≤–æ–ª—è–µ—Ç, –∏–Ω–∞—á–µ –ø—Ä–æ—Å—Ç–æ–π count)
                SELECT bid, sum(abalance) FROM pgbench_accounts GROUP BY bid ORDER BY sum(abalance) DESC LIMIT 5;
            \endif
            """

            script_path = self._copy_script_to_container(sql_script, "olap.sql")

            result = self._run_pgbench_custom(script_path, duration, clients=4, threads=2, test_name="OLAP")

            return self._process_results(result.stdout, profile_name, "OLAP", duration, 4)

        except Exception as e:
            return self._handle_error(e, profile_name)

    def run_disk_bound_olap_test(self, profile_name, duration=30):
        """
        –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞, —É–ø–∏—Ä–∞—é—â–∞—è—Å—è –≤ I/O: –±–æ–ª—å—à–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ —Å–∫–∞–Ω—ã.
        """
        try:
            print(f" Starting Disk-Bound OLAP test for {profile_name}...")
            self._create_disk_bound_table()

            # –°–ª–æ–∂–Ω—ã–π –∑–∞–ø—Ä–æ—Å —Å —Ñ—É–Ω–∫—Ü–∏–µ–π, –∑–∞—Å—Ç–∞–≤–ª—è—é—â–∏–π –¥–µ–ª–∞—Ç—å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π —Å–∫–∞–Ω
            sql_script = """
            -- –í—ã–ø–æ–ª–Ω—è–µ–º –∞–≥—Ä–µ–≥–∞—Ü–∏—é –ø–æ –±–æ–ª—å—à–æ–º—É –ø–æ–ª—é –±–µ–∑ –∏–Ω–¥–µ–∫—Å–∞, —á—Ç–æ–±—ã —É–±–µ–¥–∏—Ç—å—Å—è –≤ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–∏ –¥–∏—Å–∫–∞.
            SELECT count(*), max(random_data)
            FROM disk_bound_data
            WHERE random_data LIKE 'A%';
            """

            script_path = self._copy_script_to_container(sql_script, "disk_olap.sql")

            clients = 2 # –ù–∏–∑–∫–æ–µ —á–∏—Å–ª–æ –∫–ª–∏–µ–Ω—Ç–æ–≤, —á—Ç–æ–±—ã —Ç–µ—Å—Ç –±—ã–ª –¥–æ–ª–≥–∏–º
            threads = 1
            result = self._run_pgbench_custom(script_path, duration, clients, threads, test_name="DISK_OLAP")

            return self._process_results(result.stdout, profile_name, "DISK_OLAP", duration, clients)

        except Exception as e:
            return self._handle_error(e, profile_name)

    def run_iot_test(self, profile_name, duration=30):
        """
        IoT –Ω–∞–≥—Ä—É–∑–∫–∞: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –±—ã—Å—Ç—Ä–∞—è –≤—Å—Ç–∞–≤–∫–∞ –º–µ–ª–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö.
        """
        try:
            print(f" Starting IoT test for {profile_name}...")
            self._create_iot_tables()

            sql_script = """
            INSERT INTO iot_sensor_data (sensor_id, value, timestamp)
            VALUES (floor(random() * 1000)::int, random() * 100, NOW());

            INSERT INTO iot_metrics (device_id, metric_type, value, recorded_at)
            VALUES (floor(random() * 100)::int, 1, random() * 500, NOW());
            """

            script_path = self._copy_script_to_container(sql_script, "iot.sql")

            clients = 30
            threads = 4
            result = self._run_pgbench_custom(script_path, duration, clients, threads, test_name="IoT")

            return self._process_results(result.stdout, profile_name, "IoT", duration, clients)

        except Exception as e:
            return self._handle_error(e, profile_name)

    def run_mixed_test(self, profile_name, duration=30):
        """
        –°–º–µ—à–∞–Ω–Ω–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞: –ß—Ç–µ–Ω–∏–µ (50%), –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ (30%), –í—Å—Ç–∞–≤–∫–∞ (20%).
        """
        try:
            print(f" Starting Mixed test for {profile_name}...")
            self._initialize_pgbench(scale=5)

            sql_script = """
            \set r random(1, 100)
            \if :r <= 50
                -- 50% Read
                SELECT abalance FROM pgbench_accounts WHERE aid = :r;
            \elif :r <= 80
                -- 30% Update
                UPDATE pgbench_accounts SET abalance = abalance + 1 WHERE aid = :r;
            \else
                -- 20% Insert
                INSERT INTO pgbench_history (tid, bid, aid, delta, mtime) VALUES (1, 1, 1, 1, NOW());
            \endif
            """

            script_path = self._copy_script_to_container(sql_script, "mixed.sql")
            result = self._run_pgbench_custom(script_path, duration, clients=16, threads=4, test_name="Mixed")

            return self._process_results(result.stdout, profile_name, "Mixed", duration, 16)

        except Exception as e:
            return self._handle_error(e, profile_name)

    def run_read_only_test(self, profile_name, duration=30):
        """
        –¢–µ—Å—Ç —Ç–æ–ª—å–∫–æ –¥–ª—è —á—Ç–µ–Ω–∏—è (Web / Read-Only): –≤—ã—Å–æ–∫–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö.
        """
        try:
            print(f" Starting Read-Only test for {profile_name}...")
            self._initialize_pgbench(scale=10)

            sql_script = """
            -- –í—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω—É—é –∑–∞–ø–∏—Å—å, –∏–º–∏—Ç–∏—Ä—É—è —á—Ç–µ–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã/–æ–±—ä–µ–∫—Ç–∞
            SELECT abalance, filler FROM pgbench_accounts WHERE aid = :aid;
            """

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç, –Ω–æ —Å –≤—ã—Å–æ–∫–æ–π –∫–æ–Ω–∫—É—Ä–µ–Ω—Ü–∏–µ–π –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–µ—à–∞
            script_path = self._copy_script_to_container(sql_script, "readonly.sql")

            clients = 50
            threads = 8
            result = self._run_pgbench_custom(script_path, duration, clients, threads, test_name="READ_ONLY")

            return self._process_results(result.stdout, profile_name, "READ_ONLY", duration, clients)

        except Exception as e:
            return self._handle_error(e, profile_name)

    def run_bulk_load_test(self, profile_name, duration=30):
        """
        –ú–∞—Å—Å–æ–≤–∞—è –∑–∞–ª–∏–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö (Bulk Load): –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω—ã–µ INSERT'—ã, –Ω–∞–≥—Ä—É–∑–∫–∞ –Ω–∞ WAL/Checkpoints.
        """
        try:
            print(f" Starting Bulk Load test for {profile_name}...")
            self._create_bulk_table()

            sql_script = """
            INSERT INTO bulk_data (col1, col2, col3)
            SELECT i, md5(random()::text), now() FROM generate_series(1, 100) AS s(i);
            """

            # –ú–Ω–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–æ–≤, —á—Ç–æ–±—ã –æ–±–µ—Å–ø–µ—á–∏—Ç—å –≤—ã—Å–æ–∫—É—é —Å–∫–æ—Ä–æ—Å—Ç—å –∑–∞–ø–∏—Å–∏
            script_path = self._copy_script_to_container(sql_script, "bulk_load.sql")

            clients = 40
            threads = 8
            result = self._run_pgbench_custom(script_path, duration, clients, threads, test_name="BULK_LOAD")

            # –û—á–∏—Å—Ç–∫–∞ —Ç–∞–±–ª–∏—Ü—ã
            self._exec_sql("TRUNCATE TABLE bulk_data;")

            return self._process_results(result.stdout, profile_name, "BULK_LOAD", duration, clients)

        except Exception as e:
            return self._handle_error(e, profile_name)

    def run_tpcc_test(self, profile_name, duration=60):
        """
        –ü—ã—Ç–∞–µ—Ç—Å—è –∑–∞–ø—É—Å—Ç–∏—Ç—å HammerDB. –ï—Å–ª–∏ –Ω–µ—Ç - –º–æ—â–Ω–∞—è —ç–º—É–ª—è—Ü–∏—è —á–µ—Ä–µ–∑ pgbench.
        """
        try:
            print(f" Starting TPC-C test for {profile_name}...")

            check = subprocess.run(["docker", "ps", "-q", "-f", f"name={self.hammerdb_container}"], capture_output=True, text=True)

            if check.stdout.strip():
                print(" Using HammerDB container...")
                cmd = ["docker", "exec", self.hammerdb_container, "hammerdbcli", "auto", "/hammerdb/run_tpcc.tcl"]
                result = subprocess.run(cmd, capture_output=True, text=True)
                tps, latency = self._parse_hammerdb_output(result.stdout)

                results = {
                    'profile': profile_name, 'test_type': 'TPC-C',
                    'tps': tps, 'tpm': tps * 60, 'avg_latency': latency,
                    'duration_minutes': round(duration/60, 2), 'clients': 4
                }
            else:
                print(" HammerDB not found. Running TPC-C simulation via pgbench...")

                sql_script = """
                BEGIN;
                -- Payment Transaction Logic
                UPDATE pgbench_branches SET bbalance = bbalance + 10 WHERE bid = :scale;
                UPDATE pgbench_tellers SET tbalance = tbalance + 10 WHERE tid = :scale;
                UPDATE pgbench_accounts SET abalance = abalance + 10 WHERE aid = :scale;
                INSERT INTO pgbench_history (tid, bid, aid, delta, mtime) VALUES (1, 1, 1, 10, NOW());
                -- New Order Check
                SELECT abalance FROM pgbench_accounts WHERE aid = :scale;
                COMMIT;
                """
                script_path = self._copy_script_to_container(sql_script, "tpcc_sim.sql")
                res = self._run_pgbench_custom(script_path, duration, clients=10, threads=2, test_name="TPC-C (Sim)")
                return self._process_results(res.stdout, profile_name, "TPC-C", duration, 10)

            self._save_results(results)
            print(f" TPC-C test completed: {results['tps']:.1f} TPS")
            return results

        except Exception as e:
            return self._handle_error(e, profile_name)


    def _process_results(self, stdout, profile_name, test_type, duration, clients):
        """–ü–∞—Ä—Å–∏–Ω–≥ –≤—ã–≤–æ–¥–∞ pgbench –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –ë–î"""
        tps, avg_latency = self._parse_pgbench_output(stdout)

        results = {
            'profile': profile_name,
            'test_type': test_type,
            'tps': round(tps, 2),
            'tpm': round(tps * 60, 2),
            'avg_latency': round(avg_latency, 2),
            'duration_minutes': round(duration / 60, 2),
            'clients': clients,
            'timestamp': datetime.now().isoformat()
        }

        self._save_results(results)
        print(f" {test_type} completed: {tps:.1f} TPS, {avg_latency:.2f}ms")
        return results

    def _initialize_pgbench(self, scale=5):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è pgbench —Ç–∞–±–ª–∏—Ü, –µ—Å–ª–∏ –æ–Ω–∏ –ø—É—Å—Ç—ã"""
        try:
            check_cmd = ["docker", "exec", "-i", self.container_name, "psql", "-U", "user", "-d", "mydb", "-tAc", "SELECT count(*) FROM pgbench_accounts"]
            res = subprocess.run(check_cmd, capture_output=True, text=True)

            if res.returncode == 0 and res.stdout.strip().isdigit() and int(res.stdout.strip()) > 0:
                return

            print(f" Initializing pgbench (Scale {scale})...")
            init_cmd = ["docker", "exec", "-i", self.container_name, "pgbench", "-i", "-s", str(scale), "--foreign-keys", "-U", "user", "mydb"]
            subprocess.run(init_cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        except Exception:
            pass

    def _create_iot_tables(self):
        """–°–æ–∑–¥–∞–µ—Ç —Ç–∞–±–ª–∏—Ü—ã –¥–ª—è IoT —Ç–µ—Å—Ç–∞"""
        sql = """
        CREATE TABLE IF NOT EXISTS iot_sensor_data (id SERIAL, sensor_id INT, value DECIMAL, timestamp TIMESTAMP);
        CREATE TABLE IF NOT EXISTS iot_metrics (id SERIAL, device_id INT, metric_type INT, value DECIMAL, recorded_at TIMESTAMP);
        TRUNCATE TABLE iot_sensor_data; -- –û—á–∏—Å—Ç–∫–∞ –¥–ª—è —á–∏—Å—Ç–æ—Ç—ã —Ç–µ—Å—Ç–∞
        """
        self._exec_sql(sql)

    def _create_olap_indexes(self):
        """–°–æ–∑–¥–∞–µ—Ç –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è JOIN'–æ–≤"""
        sql = "CREATE INDEX IF NOT EXISTS idx_pgbench_accounts_bid ON pgbench_accounts(bid);"
        self._exec_sql(sql)

    def _create_bulk_table(self):
        """–°–æ–∑–¥–∞–µ—Ç —Ç–∞–±–ª–∏—Ü—É –¥–ª—è Bulk Load —Ç–µ—Å—Ç–∞"""
        sql = """
        CREATE TABLE IF NOT EXISTS bulk_data (
            id BIGSERIAL PRIMARY KEY,
            col1 INT,
            col2 VARCHAR(32),
            col3 TIMESTAMP
        );
        """
        self._exec_sql(sql)

    def _create_disk_bound_table(self):
        """–°–æ–∑–¥–∞–µ—Ç –±–æ–ª—å—à—É—é —Ç–∞–±–ª–∏—Ü—É –±–µ–∑ –∏–Ω–¥–µ–∫—Å–æ–≤ –¥–ª—è Disk-Bound OLAP —Ç–µ—Å—Ç–∞"""
        sql = """
        CREATE TABLE IF NOT EXISTS disk_bound_data (
            id BIGSERIAL PRIMARY KEY,
            random_data VARCHAR(100) DEFAULT md5(random()::text),
            payload TEXT
        );

        -- –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å–ª–∏ —Ç–∞–±–ª–∏—Ü–∞ –ø—É—Å—Ç–∞, –∑–∞–ø–æ–ª–Ω—è–µ–º –µ–µ (1–ú —Å—Ç—Ä–æ–∫ ~ 100MB)
        DO $$
        BEGIN
            IF (SELECT count(*) FROM disk_bound_data) < 1000000 THEN
                TRUNCATE TABLE disk_bound_data;
                INSERT INTO disk_bound_data (payload)
                SELECT repeat('X', 500)
                FROM generate_series(1, 1000000);
            END IF;
        END
        $$;

        DROP INDEX IF EXISTS disk_bound_data_random_data_idx; -- –£–±–∏—Ä–∞–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–π –∏–Ω–¥–µ–∫—Å
        """
        self._exec_sql(sql)


    def _exec_sql(self, sql):
        cmd = ["docker", "exec", "-i", self.container_name, "psql", "-U", "user", "-d", "mydb", "-c", sql]
        subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

    def _parse_pgbench_output(self, output):
        tps = 0.0
        latency = 0.0
        for line in output.splitlines():
            # tps = 1234.567890 (without initial connection time)
            if "tps =" in line:
                try:
                    parts = line.split("=")
                    tps = float(parts[1].split()[0])
                except: pass
            # latency average = 1.234 ms
            if "latency average =" in line:
                try:
                    parts = line.split("=")
                    latency = float(parts[1].split()[0])
                except: pass
        return tps, latency

    def _parse_hammerdb_output(self, output):
        tps = 0.0
        latency = 0.0
        if "tpmC" in output:
            try:
                tpm = float(re.search(r'tpmC\s*[:=]\s*(\d+\.?\d*)', output).group(1))
                tps = tpm / 60
            except: pass
        return tps, latency

    def _save_results(self, results):
        try:
            conn = psycopg2.connect(**self.db_config)
            cur = conn.cursor()
            cur.execute("""
                INSERT INTO benchmark_results
                (profile_name, test_type, tpm, nopm, avg_latency, tps, duration_minutes, clients)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
            """, (
                results.get('profile'), results.get('test_type'), results.get('tpm', 0),
                0, results.get('avg_latency', 0), results.get('tps', 0),
                results.get('duration_minutes'), results.get('clients')
            ))
            conn.commit()
            conn.close()
        except Exception as e:
            print(f" DB Save Error: {e}")

    def cleanup_failed_tests(self):
        try:
            conn = psycopg2.connect(**self.db_config)
            cur = conn.cursor()
            cur.execute("DELETE FROM benchmark_results WHERE tps IS NULL OR tps <= 0")
            count = cur.rowcount
            conn.commit()
            conn.close()
            return count
        except: return 0

    def get_comparison_report(self):
        try:
            conn = psycopg2.connect(**self.db_config)
            cur = conn.cursor()
            cur.execute("""
                SELECT profile_name, test_type, ROUND(AVG(tps), 2), ROUND(AVG(tpm), 2),
                       ROUND(AVG(avg_latency), 4), COUNT(*)
                FROM benchmark_results WHERE tps > 0
                GROUP BY profile_name, test_type ORDER BY AVG(tps) DESC
            """)
            return cur.fetchall()
        except: return []

    def _handle_error(self, e, profile):
        msg = f"Test failed: {str(e)}"
        print(f" {msg}")
        return {'error': msg, 'profile': profile}
