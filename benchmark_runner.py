import subprocess
import time
import re
from datetime import datetime
import psycopg2
from config import DB_CONFIG

class BenchmarkRunner:
    def __init__(self, db_config):
        self.db_config = db_config

    def run_oltp_test(self, profile_name, clients=8, duration=30):
        """–¢–µ—Å—Ç–∏—Ä–æ–≤—â–∏–∫ –¥–ª—è OLTP –Ω–∞–≥—Ä—É–∑–∫–∏"""
        try:
            print(f"üöÄ Starting OLTP test for {profile_name}...")

            # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è pgbench
            self._initialize_pgbench(scale=10)

            # –ó–∞–ø—É—Å–∫ OLTP —Ç–µ—Å—Ç–∞
            run_cmd = [
                "docker", "exec", "-i", "vtb_postgres",
                "pgbench", "-c", str(clients), "-j", "2", "-T", str(duration),
                "-U", "user", "mydb", "-r", "-P", "2"
            ]

            print(f"üîß Running: {' '.join(run_cmd)}")
            result = subprocess.run(run_cmd, capture_output=True, text=True)

            # –ü–∞—Ä—Å–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            tps, avg_latency = self._parse_pgbench_output(result.stdout)
            tpm = tps * 60

            results = {
                'profile': profile_name,
                'test_type': 'OLTP',
                'tps': round(tps, 2),
                'tpm': round(tpm, 2),
                'avg_latency': round(avg_latency, 2),
                'duration_minutes': round(duration / 60, 2),
                'clients': clients,
                'timestamp': datetime.now().isoformat()
            }

            self._save_results(results)
            print(f"‚úÖ OLTP test completed: {tps:.1f} TPS, {avg_latency:.2f}ms latency")
            return results

        except Exception as e:
            error_msg = f"OLTP test failed: {str(e)}"
            print(f"‚ùå {error_msg}")
            return {'error': error_msg, 'profile': profile_name}

    def run_olap_test(self, profile_name, duration=30):
        """–¢–µ—Å—Ç–∏—Ä–æ–≤—â–∏–∫ –¥–ª—è OLAP –Ω–∞–≥—Ä—É–∑–∫–∏ - –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–ø—Ä–æ—Å—ã"""
        try:
            print(f"üöÄ Starting OLAP test for {profile_name}...")

            # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏
            self._create_olap_test_data()

            container = "vtb_postgres"
            heavy_queries = [
                # –¢—è–∂–µ–ª—ã–π –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –∑–∞–ø—Ä–æ—Å 1
                """
                SELECT bid, count(*) as account_count, avg(abalance) as avg_balance,
                       sum(abalance) as total_balance
                FROM pgbench_accounts
                GROUP BY bid
                ORDER BY total_balance DESC;
                """,
                # –¢—è–∂–µ–ª—ã–π –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –∑–∞–ø—Ä–æ—Å 2
                """
                SELECT a.aid, b.bbalance, t.tbalance, a.abalance,
                       (a.abalance + b.bbalance + t.tbalance) as total
                FROM pgbench_accounts a
                JOIN pgbench_branches b ON a.bid = b.bid
                JOIN pgbench_tellers t ON a.bid = t.bid
                WHERE a.abalance > 0
                ORDER BY total DESC
                LIMIT 1000;
                """,
                # –¢—è–∂–µ–ª—ã–π –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –∑–∞–ø—Ä–æ—Å 3
                """
                WITH account_stats AS (
                    SELECT bid,
                           count(*) as cnt,
                           avg(abalance) as avg_bal,
                           stddev(abalance) as std_bal
                    FROM pgbench_accounts
                    GROUP BY bid
                )
                SELECT b.bid, b.bbalance, a.cnt, a.avg_bal, a.std_bal
                FROM pgbench_branches b
                JOIN account_stats a ON b.bid = a.bid
                ORDER BY a.avg_bal DESC;
                """
            ]

            start_time = time.time()
            completed_queries = 0
            total_latency = 0.0

            while time.time() - start_time < duration:
                for i, query in enumerate(heavy_queries):
                    if time.time() - start_time >= duration:
                        break

                    cmd = ["docker", "exec", "-i", container, "psql", "-U", "user", "-d", "mydb", "-c", query]

                    query_start = time.time()
                    result = subprocess.run(cmd, capture_output=True, text=True)
                    query_latency = (time.time() - query_start) * 1000  # –≤ ms

                    if result.returncode == 0:
                        completed_queries += 1
                        total_latency += query_latency
                    else:
                        print(f"Query {i+1} failed: {result.stderr}")

                    # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                    time.sleep(0.5)

            actual_duration = time.time() - start_time
            qps = completed_queries / actual_duration if actual_duration > 0 else 0
            avg_latency = total_latency / completed_queries if completed_queries > 0 else 0

            results = {
                'profile': profile_name,
                'test_type': 'OLAP',
                'tps': round(qps, 2),  # Queries per second
                'tpm': round(qps * 60, 2),
                'avg_latency': round(avg_latency, 2),
                'duration_minutes': round(actual_duration / 60, 2),
                'clients': 1,  # OLAP –æ–±—ã—á–Ω–æ single-threaded
                'timestamp': datetime.now().isoformat()
            }

            self._save_results(results)
            print(f"‚úÖ OLAP test completed: {qps:.1f} QPS, {avg_latency:.2f}ms latency")
            return results

        except Exception as e:
            error_msg = f"OLAP test failed: {str(e)}"
            print(f"‚ùå {error_msg}")
            return {'error': error_msg, 'profile': profile_name}

    def run_iot_test(self, profile_name, duration=30):
        """–¢–µ—Å—Ç–∏—Ä–æ–≤—â–∏–∫ –¥–ª—è IoT –Ω–∞–≥—Ä—É–∑–∫–∏ - –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–∞—è –∑–∞–ø–∏—Å—å"""
        try:
            print(f"üöÄ Starting IoT test for {profile_name}...")

            # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É –¥–ª—è IoT —Ç–µ—Å—Ç–æ–≤ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            self._create_iot_test_table()

            container = "vtb_postgres"

            # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è IoT
            insert_queries = [
                # –ë—ã—Å—Ç—Ä–∞—è –≤—Å—Ç–∞–≤–∫–∞ 1
                """
                INSERT INTO iot_sensor_data
                (sensor_id, value, timestamp)
                VALUES (
                    floor(random() * 1000)::int,
                    random() * 100,
                    NOW() - (random() * interval '1 day')
                );
                """,
                # –ë—ã—Å—Ç—Ä–∞—è –≤—Å—Ç–∞–≤–∫–∞ 2
                """
                INSERT INTO iot_metrics
                (device_id, metric_type, value, recorded_at)
                VALUES (
                    floor(random() * 100)::int,
                    floor(random() * 10)::int,
                    random() * 1000,
                    NOW()
                );
                """
            ]

            start_time = time.time()
            completed_inserts = 0
            total_latency = 0.0

            while time.time() - start_time < duration:
                for i, query in enumerate(insert_queries):
                    if time.time() - start_time >= duration:
                        break

                    cmd = ["docker", "exec", "-i", container, "psql", "-U", "user", "-d", "mydb", "-c", query]

                    insert_start = time.time()
                    result = subprocess.run(cmd, capture_output=True, text=True)
                    insert_latency = (time.time() - insert_start) * 1000  # –≤ ms

                    if result.returncode == 0:
                        completed_inserts += 1
                        total_latency += insert_latency
                    else:
                        print(f"Insert {i+1} failed: {result.stderr}")

                    # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø–∞—É–∑–∞ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                    time.sleep(0.01)

            actual_duration = time.time() - start_time
            ips = completed_inserts / actual_duration if actual_duration > 0 else 0
            avg_latency = total_latency / completed_inserts if completed_inserts > 0 else 0

            results = {
                'profile': profile_name,
                'test_type': 'IoT',
                'tps': round(ips, 2),  # Inserts per second
                'tpm': round(ips * 60, 2),
                'avg_latency': round(avg_latency, 2),
                'duration_minutes': round(actual_duration / 60, 2),
                'clients': 1,
                'timestamp': datetime.now().isoformat()
            }

            self._save_results(results)
            print(f"‚úÖ IoT test completed: {ips:.1f} IPS, {avg_latency:.2f}ms latency")
            return results

        except Exception as e:
            error_msg = f"IoT test failed: {str(e)}"
            print(f"‚ùå {error_msg}")
            return {'error': error_msg, 'profile': profile_name}

    def run_mixed_test(self, profile_name, duration=30):
        """–¢–µ—Å—Ç–∏—Ä–æ–≤—â–∏–∫ –¥–ª—è —Å–º–µ—à–∞–Ω–Ω–æ–π –Ω–∞–≥—Ä—É–∑–∫–∏"""
        try:
            print(f"üöÄ Starting Mixed test for {profile_name}...")

            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è mixed —Ç–µ—Å—Ç–∞
            self._initialize_pgbench(scale=5)

            container = "vtb_postgres"

            # –°–º–µ—à–∞–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã: —á—Ç–µ–Ω–∏–µ + –∑–∞–ø–∏—Å—å + –∞–Ω–∞–ª–∏—Ç–∏–∫–∞
            mixed_queries = [
                # OLTP-like: –∫–æ—Ä–æ—Ç–∫–∏–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
                "UPDATE pgbench_accounts SET abalance = abalance + 1 WHERE aid = 1;",
                # OLAP-like: –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–ø—Ä–æ—Å—ã
                "SELECT count(*), avg(abalance) FROM pgbench_accounts WHERE bid = 1;",
                # IoT-like: –≤—Å—Ç–∞–≤–∫–∏
                "INSERT INTO pgbench_history (tid, bid, aid, delta, mtime) VALUES (1, 1, 1, 1, NOW());",
                # –ß—Ç–µ–Ω–∏–µ
                "SELECT abalance FROM pgbench_accounts WHERE aid = 1;"
            ]

            start_time = time.time()
            completed_operations = 0
            total_latency = 0.0

            while time.time() - start_time < duration:
                for i, query in enumerate(mixed_queries):
                    if time.time() - start_time >= duration:
                        break

                    cmd = ["docker", "exec", "-i", container, "psql", "-U", "user", "-d", "mydb", "-c", query]

                    op_start = time.time()
                    result = subprocess.run(cmd, capture_output=True, text=True)
                    op_latency = (time.time() - op_start) * 1000  # –≤ ms

                    if result.returncode == 0:
                        completed_operations += 1
                        total_latency += op_latency
                    else:
                        print(f"Operation {i+1} failed: {result.stderr}")

                    time.sleep(0.1)

            actual_duration = time.time() - start_time
            ops = completed_operations / actual_duration if actual_duration > 0 else 0
            avg_latency = total_latency / completed_operations if completed_operations > 0 else 0

            results = {
                'profile': profile_name,
                'test_type': 'Mixed',
                'tps': round(ops, 2),  # Operations per second
                'tpm': round(ops * 60, 2),
                'avg_latency': round(avg_latency, 2),
                'duration_minutes': round(actual_duration / 60, 2),
                'clients': 1,
                'timestamp': datetime.now().isoformat()
            }

            self._save_results(results)
            print(f"‚úÖ Mixed test completed: {ops:.1f} OPS, {avg_latency:.2f}ms latency")
            return results

        except Exception as e:
            error_msg = f"Mixed test failed: {str(e)}"
            print(f"‚ùå {error_msg}")
            return {'error': error_msg, 'profile': profile_name}

    def _initialize_pgbench(self, scale=5):
        """–ù–∞–¥–µ–∂–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è pgbench"""
        try:
            print("üîÑ Initializing pgbench...")

            # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –±–∞–∑–∞
            check_cmd = [
                "docker", "exec", "-i", "vtb_postgres",
                "psql", "-U", "user", "-d", "mydb", "-c", "SELECT 1;"
            ]
            subprocess.run(check_cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

            # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –ø–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º pgbench
            init_cmd = [
                "docker", "exec", "-i", "vtb_postgres",
                "pgbench", "-i", "-s", str(scale), "-U", "user", "mydb"
            ]

            result = subprocess.run(init_cmd, capture_output=True, text=True)

            if result.returncode != 0:
                if "already exists" not in result.stderr:
                    print(f"‚ö†Ô∏è  Init warning: {result.stderr}")
                # –í—Å–µ —Ä–∞–≤–Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º, —Ç.–∫. —Ç–∞–±–ª–∏—Ü—ã –º–æ–≥—É—Ç —Å—É—â–µ—Å—Ç–≤–æ–≤–∞—Ç—å
            else:
                print("‚úÖ Pgbench initialized successfully")

        except Exception as e:
            print(f"‚ùå Pgbench initialization failed: {e}")

    def _create_olap_test_data(self):
        """–°–æ–∑–¥–∞–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è OLAP —Ç–µ—Å—Ç–æ–≤"""
        try:
            container = "vtb_postgres"

            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
            index_queries = [
                "CREATE INDEX IF NOT EXISTS idx_accounts_bid ON pgbench_accounts(bid);",
                "CREATE INDEX IF NOT EXISTS idx_accounts_balance ON pgbench_accounts(abalance);",
                "CREATE INDEX IF NOT EXISTS idx_history_mtime ON pgbench_history(mtime);"
            ]

            for query in index_queries:
                cmd = ["docker", "exec", "-i", container, "psql", "-U", "user", "-d", "mydb", "-c", query]
                subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

            print("‚úÖ OLAP test data prepared")

        except Exception as e:
            print(f"‚ùå OLAP data preparation failed: {e}")

    def _create_iot_test_table(self):
        """–°–æ–∑–¥–∞–µ—Ç —Ç–∞–±–ª–∏—Ü—ã –¥–ª—è IoT —Ç–µ—Å—Ç–æ–≤"""
        try:
            container = "vtb_postgres"

            create_tables = [
                """
                CREATE TABLE IF NOT EXISTS iot_sensor_data (
                    id SERIAL PRIMARY KEY,
                    sensor_id INTEGER,
                    value DECIMAL(10,2),
                    timestamp TIMESTAMP,
                    created_at TIMESTAMP DEFAULT NOW()
                );
                """,
                """
                CREATE TABLE IF NOT EXISTS iot_metrics (
                    id SERIAL PRIMARY KEY,
                    device_id INTEGER,
                    metric_type INTEGER,
                    value DECIMAL(10,2),
                    recorded_at TIMESTAMP DEFAULT NOW()
                );
                """,
                """
                CREATE INDEX IF NOT EXISTS idx_sensor_timestamp ON iot_sensor_data(timestamp);
                """,
                """
                CREATE INDEX IF NOT EXISTS idx_metrics_recorded ON iot_metrics(recorded_at);
                """
            ]

            for query in create_tables:
                cmd = ["docker", "exec", "-i", container, "psql", "-U", "user", "-d", "mydb", "-c", query]
                subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

            print("‚úÖ IoT test tables created")

        except Exception as e:
            print(f"‚ùå IoT table creation failed: {e}")

    def _parse_pgbench_output(self, output):
        """–ü–∞—Ä—Å–∏—Ç –≤—ã–≤–æ–¥ pgbench"""
        tps = 0.0
        avg_latency = 0.0

        # –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è TPS
        tps_patterns = [
            r'tps = (\d+\.\d+) \(without initial connection time\)',
            r'tps = (\d+\.\d+) \(including connections establishing\)',
            r'tps = (\d+\.\d+)',
        ]

        for pattern in tps_patterns:
            match = re.search(pattern, output)
            if match:
                tps = float(match.group(1))
                break

        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è latency
        latency_patterns = [
            r'latency average = (\d+\.\d+) ms',
            r'avg latency\s*=\s*(\d+\.\d+) ms',
        ]

        for pattern in latency_patterns:
            match = re.search(pattern, output)
            if match:
                avg_latency = float(match.group(1))
                break

        return tps, avg_latency

    def _save_results(self, results):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –ë–î"""
        try:
            conn = psycopg2.connect(**self.db_config)
            cur = conn.cursor()

            cur.execute("""
                INSERT INTO benchmark_results
                (profile_name, test_type, tpm, nopm, avg_latency, tps, duration_minutes, clients)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
            """, (
                results.get('profile'),
                results.get('test_type'),
                results.get('tpm', 0),
                results.get('nopm', 0),
                results.get('avg_latency', 0),
                results.get('tps', 0),
                results.get('duration_minutes', 0),
                results.get('clients', 0)
            ))

            conn.commit()
            conn.close()
            print(f"üíæ Results saved for {results.get('profile')}")

        except Exception as e:
            print(f"‚ùå Error saving results: {e}")

    def get_comparison_report(self):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –ø—Ä–æ—Ñ–∏–ª–µ–π"""
        try:
            conn = psycopg2.connect(**self.db_config)
            cur = conn.cursor()

            cur.execute("""
                SELECT
                    profile_name,
                    test_type,
                    ROUND(AVG(COALESCE(tps, 0)), 2) as avg_tps,
                    ROUND(AVG(COALESCE(tpm, 0)), 2) as avg_tpm,
                    ROUND(AVG(COALESCE(avg_latency, 0)), 4) as avg_latency,
                    COUNT(*) as test_count
                FROM benchmark_results
                WHERE tps > 0
                GROUP BY profile_name, test_type
                ORDER BY avg_tps DESC
            """)

            results = cur.fetchall()
            conn.close()

            return results

        except Exception as e:
            print(f"‚ùå Error generating report: {e}")
            return []

    def cleanup_failed_tests(self):
        """–£–¥–∞–ª—è–µ—Ç –∑–∞–ø–∏—Å–∏ —Ç–µ—Å—Ç–æ–≤ —Å –æ—à–∏–±–∫–∞–º–∏"""
        try:
            conn = psycopg2.connect(**self.db_config)
            cur = conn.cursor()

            cur.execute("""
                DELETE FROM benchmark_results
                WHERE tps IS NULL OR tps <= 0
            """)

            deleted_count = cur.rowcount
            conn.commit()
            conn.close()

            print(f"üßπ Cleaned up {deleted_count} failed test records")
            return deleted_count

        except Exception as e:
            print(f"‚ùå Error cleaning up failed tests: {e}")
            return 0
